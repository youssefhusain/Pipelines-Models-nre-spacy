# -*- coding: utf-8 -*-
"""spacy nre.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y4-YdcKjBinM6NW-Kuno5RiakLeyRh3G
"""

import spacy
from spacy.tokens import DocBin
from spacy.util import minibatch, compounding
from pathlib import Path



TRAIN_DATA = [
    ("Barack Obama was born in Hawaii.", {"entities": [(0, 12, "PERSON"), (25, 31, "GPE")]}),
    ("Apple is looking at buying a U.K. startup.", {"entities": [(0, 5, "ORG"), (27, 30, "GPE")]}),
    ("Elon Musk founded SpaceX.", {"entities": [(0, 9, "PERSON"), (18, 24, "ORG")]}),
    ("Google is a tech company.", {"entities": [(0, 6, "ORG")]}),
]

nlp = spacy.blank("en")

doc_bin = DocBin()

for text, annot in TRAIN_DATA:
    doc = nlp.make_doc(text)
    ents = []
    for start, end, label in annot["entities"]:
        span = doc.char_span(start, end, label=label)
        if span:
            ents.append(span)
    doc.ents = ents
    doc_bin.add(doc)
doc_bin.to_disk("train.spacy")
doc_bin.to_disk("dev.spacy")

!python -m spacy init config config.cfg --lang en --pipeline ner --force

!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy --verbose

import spacy

nlp_ner = spacy.load("output/model-best")
doc = nlp_ner("Barack Obama visited Berlin in 2008.")

print("\nEntities found:")
for ent in doc.ents:
    print(ent.text, "->", ent.label_)

! pip install datasets

from datasets import load_dataset
dataset = load_dataset("conll2003")

label_list = dataset["train"].features["ner_tags"].feature.names
print("NER labels:", label_list)

from tqdm import tqdm
def convert_to_spacy_format(dataset_split, nlp):
    doc_bin = DocBin()
    for example in tqdm(dataset_split):
        words = example["tokens"]
        tags = example["ner_tags"]
        doc = nlp.make_doc(" ".join(words))
        ents = []
        start = 0
        for word, tag in zip(words, tags):
            word_start = doc.text.find(word, start)
            word_end = word_start + len(word)
            if tag != 0:
                ents.append(doc.char_span(word_start, word_end, label=label_list[tag]))
            start = word_end
        ents = [e for e in ents if e is not None]
        doc.ents = ents
        doc_bin.add(doc)
    return doc_bin

nlp_blank = spacy.blank("en")

doc_bin_train = convert_to_spacy_format(dataset["train"].select(range(1000)), nlp_blank)
doc_bin_train.to_disk("train.spacy")

doc_bin_dev = convert_to_spacy_format(dataset["validation"].select(range(200)), nlp_blank)
doc_bin_dev.to_disk("dev.spacy")

!python -m spacy init config config.cfg --lang en --pipeline ner --force

!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy --verbose --gpu-id 0

nlp_trained = spacy.load("./output/model-best")

test_text = "Youssef Hussain Mahdy visited Banha ."
doc = nlp_trained(test_text)
print("\nEntities found:")
for ent in doc.ents:
    print(ent.text, "->", ent.label_)

